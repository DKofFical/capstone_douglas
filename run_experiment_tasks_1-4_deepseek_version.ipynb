{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from random import sample\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "import tiktoken\n",
    "key = \"insert_key_here\"\n",
    "\n",
    "client = OpenAI(api_key= key, base_url=\"https://api.deepseek.com\")\n",
    "# Parameters\n",
    "\n",
    "# Function\n",
    "def get_response(message, instruction):\n",
    "    response = client.chat.completions.create(\n",
    "\t\tmodel = 'deepseek-reasoner',\n",
    "        temperature = 1,\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": instruction},\n",
    "            {\"role\": \"user\", \"content\": message}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # print token usage\n",
    "    print(response.usage)\n",
    "    # return the response\n",
    "    return response.choices[0].message.content\n",
    "  \n",
    "def LM_generation(prompt, max_tokens = 10, temperature = 0.1, model = \"deepseek-reasoner\", system_msg = None, msg_history = None):\n",
    "    retry_attempt = 5\n",
    "    retry_num = 0\n",
    "    generation_success = False\n",
    "    messages = []\n",
    "    if system_msg is not None:\n",
    "        messages.append({'role':'system', 'content': system_msg})\n",
    "    if msg_history is not None:\n",
    "        messages = msg_history\n",
    "    messages.append({'role':'user', 'content':prompt})\n",
    "    while retry_num < retry_attempt and not generation_success:\n",
    "        try:\n",
    "            gen = client.chat.completions.create(\n",
    "                model = model,\n",
    "                messages = messages,\n",
    "                max_tokens = max_tokens,\n",
    "                temperature = temperature,\n",
    "                stream = False\n",
    "            ) \n",
    "            generation_success = True\n",
    "            input_tokens = gen.usage.prompt_tokens\n",
    "            output_tokens = gen.usage.completion_tokens\n",
    "        except openai.APIError as e:\n",
    "            retry_num += 1\n",
    "            generation_success = False\n",
    "            time.sleep(5)\n",
    "            # return \"openai.error.APIError\", -1, -1 \n",
    "        except openai.RateLimitError as e:\n",
    "            retry_num += 1\n",
    "            generation_success = False\n",
    "            time.sleep(30)\n",
    "        except:\n",
    "            retry_num += 1\n",
    "            generation_success = False\n",
    "            time.sleep(10)\n",
    "    \n",
    "    if generation_success:\n",
    "        if gen == None or gen.choices[0] == None or gen.choices[0].message == None or gen.choices[0].message.content == None:\n",
    "            return \"\", 0, 0\n",
    "        # return gen.choices[0].message.content.strip(), input_tokens, output_tokens\n",
    "        return gen, input_tokens, output_tokens\n",
    "    else:\n",
    "        return \"Error\", -1,-1\n",
    "\n",
    "def count_tokens(text, encoding_name = \"cl100k_base\"):\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    # print(text)\n",
    "    num_tokens = len(encoding.encode(text))\n",
    "    return num_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Open and read the JSON file\n",
    "with open('llm_ready_opentom_vfin.jsonl') as f: # ambiguous story\n",
    "    final_opentom = [json.loads(line) for line in f]\n",
    "    \n",
    "with open('llm_ready_bigtom_vfin.jsonl') as f: # ambiguous story\n",
    "    final_bigtom = [json.loads(line) for line in f]\n",
    "\n",
    "bigtom_filter = np.load('bigtom_filter.npy', allow_pickle=True)\n",
    "opentom_filter = np.load('opentom_filter.npy', allow_pickle=True)\n",
    "\n",
    "final_opentom = np.array(final_opentom)[opentom_filter]\n",
    "final_bigtom = np.array(final_bigtom)[bigtom_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID': '0-0-0',\n",
       " 'category': 'pos/hard_neg',\n",
       " 'sense': 'visual',\n",
       " 'story': 'Noor is working as a barista at a busy coffee shop.  Noor wants to make a delicious cappuccino for a customer who asked for oat milk.  Noor grabs a milk pitcher and fills it with oat milk.',\n",
       " 'event': \" A coworker, who didn't hear the customer's request, swaps the oat milk in the pitcher with almond milk while Noor is attending to another task.\",\n",
       " 'protag_name': 'Noor',\n",
       " 'percept_cue': \"As Noor pours the milk into the espresso, she notices the liquid's texture. Instead of the familiar creamy, smooth flow that oat milk typically has, the milk appears slightly more translucent, with a thinner consistency that swirls differently in the cup, creating delicate, lacy patterns.\",\n",
       " 'initial_belief': ' Noor believes that the milk pitcher contains oatmilk.',\n",
       " 'default_question': \"After the event happened, based on the main character Noor's perception of the event, which of the following statements best describes Noor's new belief?\",\n",
       " 'answer_options': ['Noor believes the milk pitcher contains oat milk.',\n",
       "  'Noor believes the milk pitcher contains almond milk.',\n",
       "  'Noor believes the milk pitcher contains soy milk.',\n",
       "  'Noor believes she does not know what type of milk is in the pitcher.'],\n",
       " 'groundtruth_classification': 'positive',\n",
       " 'belief_change_label': 1,\n",
       " 'belief_change_label_raw': 1.0,\n",
       " 'new_belief_label': 'D',\n",
       " 'new_belief_label_raw': ['B', 'D', 'D']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_bigtom[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save\n",
    "\n",
    "def save_list_of_dict(save_name, list_of_dict):\n",
    "    with open(save_name, 'wb') as f:\n",
    "        pickle.dump(list_of_dict, f)\n",
    "\n",
    "def load_list_of_dict(save_name):\n",
    "    with open(save_name, 'rb') as f:\n",
    "        loaded = pickle.load(f)\n",
    "    return loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senses = ['visual', 'auditory', 'olfactory', 'gustatory', 'tactile', 'proprio']\n",
    "num_senses = len(senses)\n",
    "# thermos can be merged with tactile, but minor issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sense_dict = {senses[i]: i for i in range(num_senses)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM Task 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer Holder - I think we should use list? Better to store answer, then process later.\n",
    "# Can hold answers in a list of dict\n",
    "# {ID, groundtruth_type, sense, option_order (B/A), llm_answer, true_answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigtom_task1_ans = [{'ID': instance['ID'], 'groundtruth_classification': instance['groundtruth_classification']\n",
    "                     , 'sense': instance['sense'],\n",
    "                     'answer_order': [[0,1], [1,0],[0,1],[1,0]], # this is the f() that can map original order to postprocess order\n",
    "                     'llm_answer': ['X','X','X','X'],\n",
    "                     'true_answer': [instance['belief_change_label'], 1 - instance['belief_change_label'], instance['belief_change_label'], 1 - instance['belief_change_label']],\n",
    "                     'reasoning_content': ['X','X','X','X']} \n",
    "                    for instance in final_bigtom]\n",
    "opentom_task1_ans = [{'ID': instance['ID'], 'groundtruth_classification': instance['groundtruth_classification']\n",
    "                     , 'sense': instance['sense'],\n",
    "                     'answer_order': [[0,1], [1,0],[0,1],[1,0]], # this is the f() that can map original order to postprocess order\n",
    "                     'llm_answer': ['X','X','X','X'],\n",
    "                     'true_answer': [instance['belief_change_label'], 1 - instance['belief_change_label'], instance['belief_change_label'], 1 - instance['belief_change_label']],\n",
    "                     'reasoning_content': ['X','X','X','X']} \n",
    "                    for instance in final_opentom]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompts\n",
    "bigtom_system = \"Story: {story} \\n\\nEvent: {event} \\n\\n\"\n",
    "bigtom_system += \"Regarding the event, the main character {protag_name} only encounters the following percept: {percept}\\n\\n\"\n",
    "bigtom_system += \"Before the event, the main character's initial belief was \\\"{initial_belief}\\\"\\n\\n\"\n",
    "bigtom_system += \"Instructions: Analyze the situation and select the most appropriate answer to the following question: \\n\\n\\n\"\n",
    "\n",
    "opentom_system = \"Story: {story} \\n\\n\"\n",
    "opentom_system += \"After the story, the main character {protag_name} only encounters the following percept: {percept}\\n\\n\"\n",
    "opentom_system += \"Before encountering the percept, the main character's initial belief was \\\"{initial_belief}\\\"\\n\\n\"\n",
    "opentom_system += \"Instructions: Analyze the situation and select the most appropriate answer to the following question: \\n\\n\\n\"\n",
    "\n",
    "\n",
    "# Needed variables: story, event, protag_name, percept, initial_belief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigtom_q1_prompt_1 = \"After the event happened, based on the main character {protag_name} perception of the event, \"\n",
    "bigtom_q1_prompt_1 += \"is the following statement about {protag_name}'s belief True or False: \\n\"\n",
    "bigtom_q1_prompt_1 += \"Statement: \\\"{initial_belief}\\\"\\n\"\n",
    "\n",
    "bigtom_q1 = [bigtom_q1_prompt_1, bigtom_q1_prompt_1]\n",
    "bigtom_q1[0] = bigtom_q1[0] + \"A. True\\nB. False\"\n",
    "bigtom_q1[1] = bigtom_q1[1] + \"A. False\\nB. True\"\n",
    "\n",
    "bigtom_q1_prompt_2 = \"Did the event cause the main character {protag_name} to change their belief?\\n\"\n",
    "bigtom_q1.append(bigtom_q1_prompt_2 + \"A. No\\nB. Yes\")\n",
    "bigtom_q1.append(bigtom_q1_prompt_2 + \"A. Yes\\nB. No\")\n",
    "\n",
    "opentom_q1_prompt_1 = \"After encountering the percept, based on the main character {protag_name}'s perception, is the following statement about Amir's belief True or False: \\n\"\n",
    "opentom_q1_prompt_1 += \"Statement: \\\"{initial_belief}\\\"\\n\"\n",
    "opentom_q1 = [opentom_q1_prompt_1, opentom_q1_prompt_1]\n",
    "opentom_q1[0] = opentom_q1[0] + \"A. True\\nB. False\"\n",
    "opentom_q1[1] = opentom_q1[1] + \"A. False\\nB. True\"\n",
    "\n",
    "opentom_q1_prompt_2 = \"Did the percept cause the main character {protag_name} to change their belief?\\n\"\n",
    "opentom_q1.append(opentom_q1_prompt_2 + \"A. No\\nB. Yes\")\n",
    "opentom_q1.append(opentom_q1_prompt_2 + \"A. Yes\\nB. No\")\n",
    "\n",
    "# Needed variable: protag_name, initial_belief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "option_dict = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
    "\n",
    "# def post_randomize_order(val, n): \n",
    "#     # val = \n",
    "#     # n = number of randomize\n",
    "\n",
    "bigtom_task2_ans = [{'ID': instance['ID'], 'groundtruth_classification': instance['groundtruth_classification']\n",
    "                     , 'sense': instance['sense'],\n",
    "                     'answer_order': [], # this is the f() that can map original order to postprocess order\n",
    "                     'llm_answer': ['X','X','X','X','X'],\n",
    "                     'true_answer': [],\n",
    "                     'true_answer_og': option_dict[instance['new_belief_label']],\n",
    "                     'reasoning_content': ['X','X','X','X','X']} \n",
    "                    for instance in final_bigtom]\n",
    "opentom_task2_ans = [{'ID': instance['ID'], 'groundtruth_classification': instance['groundtruth_classification']\n",
    "                     , 'sense': instance['sense'],\n",
    "                     'answer_order': [], # this is the f() that can map original order to postprocess order\n",
    "                     'llm_answer': ['X','X','X','X','X'],\n",
    "                     'true_answer': [],\n",
    "                     'true_answer_og': option_dict[instance['new_belief_label']],\n",
    "                     'reasoning_content': ['X','X','X','X','X']}  \n",
    "                    for instance in final_opentom]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "task2_ans = [bigtom_task2_ans, opentom_task2_ans]\n",
    "for t in task2_ans:\n",
    "    for instance in t:\n",
    "        for _ in range(5):\n",
    "            randomizer = np.random.choice(np.arange(4), 4, replace=False) # 0 --> a0, 1 --> a1\n",
    "            instance['answer_order'].append(randomizer.tolist())\n",
    "            # instance['true_answer'].append(['A','B','C','D'][randomizer[instance['true_answer_og']]])\n",
    "            true_answer_idx = np.where(randomizer == instance['true_answer_og'])[0][0]\n",
    "            instance['true_answer'].append(['A','B','C','D'][true_answer_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigtom_q2_prompt = \"{default_question}\\n\"\n",
    "bigtom_q2_prompt += \"Choose the most appropriate answer (choose one only):\\n\"\n",
    "bigtom_q2_prompt += \"A. {first}\\nB. {second}\\nC. {third}\\nD. {fourth}\"\n",
    "opentom_q2_prompt = bigtom_q2_prompt\n",
    "\n",
    "# \"After the event happened, based on the main character Noor's perception of the event, which of the following statements best describes Noor's new belief?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_jsonl(file_name, path):\n",
    "    with open(path, \"w\") as file:\n",
    "        for item in file_name:\n",
    "            json_string = json.dumps(item)\n",
    "            file.write(json_string + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose model\n",
    "model = \"deepseek-reasoner\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th story\n"
     ]
    }
   ],
   "source": [
    "# BigToM first - Task 1\n",
    "model = \"deepseek-reasoner\"\n",
    "# positives\n",
    "count = 0\n",
    "input_tokens = 0\n",
    "output_tokens = 0\n",
    "begin = time.time()\n",
    "\n",
    "\n",
    "for i in range(len(bigtom_task1_ans)): # set to len(bigtom_task1_ans) later # 50 so far\n",
    "    print(f'{i}-th story')\n",
    "    for k in range(4):\n",
    "    # for k in range(4):\n",
    "        #story, event, protag_name, percept, initial_belief\n",
    "        story = final_bigtom[i]['story']\n",
    "        event = final_bigtom[i]['event']\n",
    "        protag_name = final_bigtom[i]['protag_name']\n",
    "        percept = final_bigtom[i]['percept_cue']\n",
    "        initial_belief = final_bigtom[i]['initial_belief']\n",
    "        prompt = bigtom_system.format(story = story, event = event, protag_name = protag_name, percept = percept, initial_belief = initial_belief)\n",
    "        \n",
    "        prompt += bigtom_q1[k].format(protag_name = protag_name, initial_belief = initial_belief)\n",
    "        prompt += \"\\nProvide the answer as a single letter:\"\n",
    "\n",
    "        input_tokens += count_tokens(prompt)\n",
    "        \n",
    "        # print(prompt)\n",
    "        # print(\"input tokens = \", count_tokens(prompt), \". price (USD) is \", count_tokens(prompt)*30/1000000)\n",
    "        \n",
    "        \n",
    "        # Add back later\n",
    "        output = LM_generation(prompt, temperature = 0.5, max_tokens = 3, model = model)\n",
    "        \n",
    "        # Printouts - Remove later:\n",
    "        output = output[0]\n",
    "        reasoning_content = output.choices[0].message.reasoning_content\n",
    "        llm_answer = output.choices[0].message.content\n",
    "        llm_answer = llm_answer[0]\n",
    "        # print(reasoning_content)\n",
    "        # print(content)\n",
    "        \n",
    "        bigtom_task1_ans[i]['reasoning_content'][k] = reasoning_content\n",
    "        bigtom_task1_ans[i]['llm_answer'][k] = llm_answer\n",
    "\n",
    "                \n",
    "        output_tokens += count_tokens(llm_answer)\n",
    "        save_jsonl(bigtom_task1_ans, f'bigtom_task1_ans_{model}.jsonl')\n",
    "        # print(\"output tokens = \", count_tokens(output[0]), \". price (USD) is \", count_tokens(output[0])*60/1000000)\n",
    "                \n",
    "    if i % 5 == 0:\n",
    "        end = time.time()\n",
    "        print(f'Time taken for these 5 stories: {end-begin} seconds.')\n",
    "        begin = time.time()\n",
    "\n",
    "\n",
    "print(\"input tokens = \", input_tokens, \". price (USD) is \", input_tokens*30/1000000)\n",
    "print(\"output tokens = \", output_tokens, \". price (USD) is \", output_tokens*60/1000000)\n",
    "\n",
    "bigtom_task1_llm_answer = [instance['llm_answer'] for instance in bigtom_task1_ans]\n",
    "bigtom_task1_true_answer = [np.array(['A', 'B'])[np.array(instance['true_answer'])] for instance in bigtom_task1_ans]\n",
    "bigtom_task1_llm_answer = np.array(bigtom_task1_llm_answer)\n",
    "bigtom_task1_true_answer = np.array(bigtom_task1_true_answer)\n",
    "bigtom_task1_accuracy = (bigtom_task1_llm_answer == bigtom_task1_true_answer).mean(axis=1)\n",
    "\n",
    "gt_id = {'positive':0, 'hard_negative': 1, 'easy_negative':2}\n",
    "bigtom_task1_correct = np.zeros((100, 3, 8)) # groundtruth: pos, hard_neg, easy_neg\n",
    "bigtom_task1_total = np.zeros((100, 3, 8))\n",
    "for i, instance in enumerate(bigtom_task1_ans):\n",
    "    ider = instance['ID']\n",
    "    story_idx = int(ider.split('-')[0])\n",
    "    gt_idx = gt_id[instance['groundtruth_classification']]\n",
    "    sense_idx = sense_dict[instance['sense']]\n",
    "    bigtom_task1_total[story_idx][gt_idx][sense_idx] = 1\n",
    "    bigtom_task1_correct[story_idx][gt_idx][sense_idx] = bigtom_task1_accuracy[i]\n",
    "eps = 1e-10\n",
    "print(\"BigToM Task 1 TPR, TNR-hard, TNR-easy: \", bigtom_task1_correct.sum(axis = 0).sum(axis = 1)/(bigtom_task1_total.sum(axis = 0).sum(axis = 1) + eps))\n",
    "\n",
    "\n",
    "# positives\n",
    "count = 0\n",
    "input_tokens = 0\n",
    "output_tokens = 0\n",
    "begin = time.time()\n",
    "\n",
    "for i in range(len(opentom_task1_ans)): # set to len(bigtom_task1_ans) later # 50 so far\n",
    "    print(f'{i}-th story')\n",
    "    for k in range(4):\n",
    "        #story, event, protag_name, percept, initial_belief\n",
    "        story = final_opentom[i]['story']\n",
    "        protag_name = final_opentom[i]['protag_name']\n",
    "        percept = final_opentom[i]['percept_cue']\n",
    "        initial_belief = final_opentom[i]['initial_belief']\n",
    "        prompt = opentom_system.format(story = story, protag_name = protag_name, percept = percept, initial_belief = initial_belief)\n",
    "        \n",
    "        prompt += opentom_q1[k].format(protag_name = protag_name, initial_belief = initial_belief)\n",
    "\n",
    "        input_tokens += count_tokens(prompt)\n",
    "        \n",
    "        # print(prompt)\n",
    "        # print(\"input tokens = \", count_tokens(prompt), \". price (USD) is \", count_tokens(prompt)*30/1000000)\n",
    "        \n",
    "        \n",
    "        # Add back later\n",
    "        output = LM_generation(prompt, temperature = 0.5, max_tokens = 3, model = model)\n",
    "        \n",
    "        # Printouts - Remove later:\n",
    "        output = output[0]\n",
    "        reasoning_content = output.choices[0].message.reasoning_content\n",
    "        llm_answer = output.choices[0].message.content\n",
    "        llm_answer = llm_answer[0]\n",
    "        # print(reasoning_content)\n",
    "        # print(content)\n",
    "        \n",
    "        bigtom_task1_ans[i]['reasoning_content'][k] = reasoning_content\n",
    "        bigtom_task1_ans[i]['llm_answer'][k] = llm_answer\n",
    "\n",
    "                \n",
    "        output_tokens += count_tokens(llm_answer)\n",
    "        save_jsonl(opentom_task1_ans, f'opentom_task1_ans_{model}.jsonl')\n",
    "        # print(\"output tokens = \", count_tokens(output[0]), \". price (USD) is \", count_tokens(output[0])*60/1000000)\n",
    "                \n",
    "    if i % 5 == 0:\n",
    "        end = time.time()\n",
    "        print(f'Time taken for these 5 stories: {end-begin} seconds.')\n",
    "        begin = time.time()\n",
    "\n",
    "\n",
    "print(\"input tokens = \", input_tokens, \". price (USD) is \", input_tokens*30/1000000)\n",
    "print(\"output tokens = \", output_tokens, \". price (USD) is \", output_tokens*60/1000000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scoring\n",
    "# # Array: [story, groundtruth, sense] - correct & total\n",
    "\n",
    "# opentom_task1_llm_answer = [instance['llm_answer'] for instance in opentom_task1_ans]\n",
    "# opentom_task1_true_answer = [np.array(['A', 'B'])[np.array(instance['true_answer'])] for instance in opentom_task1_ans]\n",
    "# opentom_task1_llm_answer = np.array(opentom_task1_llm_answer)\n",
    "# opentom_task1_true_answer = np.array(opentom_task1_true_answer)\n",
    "# opentom_task1_accuracy = (opentom_task1_llm_answer == opentom_task1_true_answer).mean(axis=1)\n",
    "# gt_id = {'positive':0, 'hard_negative': 1, 'easy_negative':2}\n",
    "# opentom_task1_correct = np.zeros((121, 3, 8)) # groundtruth: pos, hard_neg, easy_neg\n",
    "# opentom_task1_total = np.zeros((121, 3, 8))\n",
    "# for i, instance in enumerate(opentom_task1_ans):\n",
    "#     ider = instance['ID']\n",
    "#     story_idx = int(ider.split('-')[0])\n",
    "#     gt_idx = gt_id[instance['groundtruth_classification']]\n",
    "#     sense_idx = sense_dict[instance['sense']]\n",
    "#     opentom_task1_total[story_idx][gt_idx][sense_idx] = 1\n",
    "#     opentom_task1_correct[story_idx][gt_idx][sense_idx] = opentom_task1_accuracy[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR, TNR-hard, TNR-easy:  [0.80837264 0.44670051 0.72932692]\n"
     ]
    }
   ],
   "source": [
    "# eps = 1e-10\n",
    "# print(\"TPR, TNR-hard, TNR-easy: \", opentom_task1_correct.sum(axis = 0).sum(axis = 1)/(opentom_task1_total.sum(axis = 0).sum(axis = 1) + eps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th story\n"
     ]
    }
   ],
   "source": [
    "# BigToM first - Task 1\n",
    "model = \"deepseek-reasoner\"\n",
    "# positives\n",
    "count = 0\n",
    "input_tokens = 0\n",
    "output_tokens = 0\n",
    "begin = time.time()\n",
    "\n",
    "\n",
    "for i in range(len(bigtom_task2_ans)): # set to len(bigtom_task1_ans) later # 50 so far\n",
    "    print(f'{i}-th story')\n",
    "    for k in range(5):\n",
    "        #story, event, protag_name, percept, initial_belief\n",
    "        story = final_bigtom[i]['story']\n",
    "        event = final_bigtom[i]['event']\n",
    "        protag_name = final_bigtom[i]['protag_name']\n",
    "        percept = final_bigtom[i]['percept_cue']\n",
    "        initial_belief = final_bigtom[i]['initial_belief']\n",
    "        prompt = bigtom_system.format(story = story, event = event, protag_name = protag_name, percept = percept, initial_belief = initial_belief)\n",
    "        \n",
    "        default_question = final_bigtom[i]['default_question']\n",
    "        randomizer = np.array(bigtom_task2_ans[i]['answer_order'][k])\n",
    "        # print(final_bigtom[i]['answer_options'])\n",
    "        # print(randomizer)\n",
    "        first = final_bigtom[i]['answer_options'][randomizer[0]]\n",
    "        second = final_bigtom[i]['answer_options'][randomizer[1]]\n",
    "        third = final_bigtom[i]['answer_options'][randomizer[2]]\n",
    "        fourth = final_bigtom[i]['answer_options'][randomizer[3]]\n",
    "        prompt += bigtom_q2_prompt.format(default_question=default_question, first=first, second=second, third=third, fourth=fourth)\n",
    "        prompt += \"\\nProvide the answer as a single letter:\"\n",
    "        \n",
    "        input_tokens += count_tokens(prompt)\n",
    "        \n",
    "        # print(prompt)\n",
    "        # print(\"input tokens = \", count_tokens(prompt), \". price (USD) is \", count_tokens(prompt)*30/1000000)\n",
    "        \n",
    "        \n",
    "        # Add back later\n",
    "        output = LM_generation(prompt, temperature = 0.5, max_tokens = 3, model = model)\n",
    "        \n",
    "        # Printouts - Remove later:\n",
    "        output = output[0]\n",
    "        reasoning_content = output.choices[0].message.reasoning_content\n",
    "        llm_answer = output.choices[0].message.content\n",
    "        llm_answer = llm_answer[0]\n",
    "        # print(reasoning_content)\n",
    "        # print(content)\n",
    "        \n",
    "        bigtom_task2_ans[i]['reasoning_content'][k] = reasoning_content\n",
    "        bigtom_task2_ans[i]['llm_answer'][k] = llm_answer\n",
    "\n",
    "                \n",
    "        output_tokens += count_tokens(llm_answer)\n",
    "        save_jsonl(bigtom_task2_ans, f'bigtom_task2_ans_{model}.jsonl')\n",
    "        # print(\"output tokens = \", count_tokens(output[0]), \". price (USD) is \", count_tokens(output[0])*60/1000000)\n",
    "                \n",
    "    if i % 5 == 0:\n",
    "        end = time.time()\n",
    "        print(f'Time taken for these 5 stories: {end-begin} seconds.')\n",
    "        begin = time.time()\n",
    "\n",
    "\n",
    "print(\"input tokens = \", input_tokens, \". price (USD) is \", input_tokens*30/1000000)\n",
    "print(\"output tokens = \", output_tokens, \". price (USD) is \", output_tokens*60/1000000)\n",
    "\n",
    "bigtom_task2_llm_answer = [instance['llm_answer'] for instance in bigtom_task2_ans]\n",
    "bigtom_task2_true_answer = [instance['true_answer'] for instance in bigtom_task2_ans]\n",
    "# bigtom_task2_llm_answer = bigtom_task2_llm_answer[0:50]\n",
    "# bigtom_task2_true_answer = bigtom_task2_true_answer[0:50]\n",
    "bigtom_task2_llm_answer = np.array(bigtom_task2_llm_answer)\n",
    "bigtom_task2_true_answer = np.array(bigtom_task2_true_answer)\n",
    "bigtom_task2_accuracy = (bigtom_task2_llm_answer == bigtom_task2_true_answer).mean(axis=1)\n",
    "\n",
    "gt_id = {'positive':0, 'hard_negative': 1, 'easy_negative':2}\n",
    "bigtom_task2_correct = np.zeros((100, 3, 8)) # groundtruth: pos, hard_neg, easy_neg\n",
    "bigtom_task2_total = np.zeros((100, 3, 8))\n",
    "for i, instance in enumerate(bigtom_task2_ans):\n",
    "    ider = instance['ID']\n",
    "    story_idx = int(ider.split('-')[0])\n",
    "    gt_idx = gt_id[instance['groundtruth_classification']]\n",
    "    sense_idx = sense_dict[instance['sense']]\n",
    "    bigtom_task2_total[story_idx][gt_idx][sense_idx] = 1\n",
    "    bigtom_task2_correct[story_idx][gt_idx][sense_idx] = bigtom_task2_accuracy[i]\n",
    "eps = 1e-10\n",
    "print(\"TPR, TNR-hard, TNR-easy: \", bigtom_task2_correct.sum(axis = 0).sum(axis = 1)/(bigtom_task2_total.sum(axis = 0).sum(axis = 1) + eps))\n",
    "\n",
    "# OpenToM first - Task 1\n",
    "# positives\n",
    "count = 0\n",
    "input_tokens = 0\n",
    "output_tokens = 0\n",
    "begin = time.time()\n",
    "\n",
    "# for i in range(2):\n",
    "for i in range(len(opentom_task2_ans)): # set to len(bigtom_task1_ans) later # 50 so far\n",
    "    print(f'{i}-th story')\n",
    "    for k in range(5):\n",
    "        #story, event, protag_name, percept, initial_belief\n",
    "        story = final_opentom[i]['story']\n",
    "        protag_name = final_opentom[i]['protag_name']\n",
    "        percept = final_opentom[i]['percept_cue']\n",
    "        initial_belief = final_opentom[i]['initial_belief']\n",
    "        prompt = opentom_system.format(story = story, protag_name = protag_name, percept = percept, initial_belief = initial_belief)\n",
    "        \n",
    "        default_question = final_opentom[i]['default_question']\n",
    "        randomizer = np.array(opentom_task2_ans[i]['answer_order'][k])\n",
    "        # print(final_bigtom[i]['answer_options'])\n",
    "        # print(randomizer)\n",
    "        first = final_opentom[i]['answer_options'][randomizer[0]]\n",
    "        second = final_opentom[i]['answer_options'][randomizer[1]]\n",
    "        third = final_opentom[i]['answer_options'][randomizer[2]]\n",
    "        fourth = final_opentom[i]['answer_options'][randomizer[3]]\n",
    "        prompt += opentom_q2_prompt.format(default_question=default_question, first=first, second=second, third=third, fourth=fourth)\n",
    "        prompt += \"\\nProvide the answer as a single letter:\"\n",
    "        \n",
    "        input_tokens += count_tokens(prompt)\n",
    "        \n",
    "        # print(prompt)\n",
    "        # print(\"input tokens = \", count_tokens(prompt), \". price (USD) is \", count_tokens(prompt)*30/1000000)\n",
    "        \n",
    "        \n",
    "        # Add back later\n",
    "        output = LM_generation(prompt, temperature = 0.5, max_tokens = 3, model = model)\n",
    "        \n",
    "        # Printouts - Remove later:\n",
    "        output = output[0]\n",
    "        reasoning_content = output.choices[0].message.reasoning_content\n",
    "        llm_answer = output.choices[0].message.content\n",
    "        llm_answer = llm_answer[0]\n",
    "        # print(reasoning_content)\n",
    "        # print(content)\n",
    "        \n",
    "        opentom_task2_ans[i]['reasoning_content'][k] = reasoning_content\n",
    "        opentom_task2_ans[i]['llm_answer'][k] = llm_answer\n",
    "\n",
    "                \n",
    "        output_tokens += count_tokens(llm_answer)\n",
    "        save_jsonl(opentom_task2_ans, f'opentom_task2_ans_{model}.jsonl')\n",
    "        # print(\"output tokens = \", count_tokens(output[0]), \". price (USD) is \", count_tokens(output[0])*60/1000000)\n",
    "                \n",
    "    if i % 5 == 0:\n",
    "        end = time.time()\n",
    "        print(f'Time taken for these 5 stories: {end-begin} seconds.')\n",
    "        begin = time.time()\n",
    "\n",
    "\n",
    "print(\"input tokens = \", input_tokens, \". price (USD) is \", input_tokens*30/1000000)\n",
    "print(\"output tokens = \", output_tokens, \". price (USD) is \", output_tokens*60/1000000)\n",
    "\n",
    "opentom_task2_llm_answer = [instance['llm_answer'] for instance in opentom_task2_ans]\n",
    "opentom_task2_true_answer = [instance['true_answer'] for instance in opentom_task2_ans]\n",
    "opentom_task2_llm_answer = np.array(opentom_task2_llm_answer)\n",
    "opentom_task2_true_answer = np.array(opentom_task2_true_answer)\n",
    "opentom_task2_accuracy = (opentom_task2_llm_answer == opentom_task2_true_answer).mean(axis=1)\n",
    "gt_id = {'positive':0, 'hard_negative': 1, 'easy_negative':2}\n",
    "opentom_task2_correct = np.zeros((121, 3, 8)) # groundtruth: pos, hard_neg, easy_neg\n",
    "opentom_task2_total = np.zeros((121, 3, 8))\n",
    "for i, instance in enumerate(opentom_task2_ans):\n",
    "    ider = instance['ID']\n",
    "    story_idx = int(ider.split('-')[0])\n",
    "    gt_idx = gt_id[instance['groundtruth_classification']]\n",
    "    sense_idx = sense_dict[instance['sense']]\n",
    "    opentom_task2_total[story_idx][gt_idx][sense_idx] = 1\n",
    "    opentom_task2_correct[story_idx][gt_idx][sense_idx] = opentom_task2_accuracy[i]\n",
    "eps = 1e-10\n",
    "print(\"TPR, TNR-hard, TNR-easy: \", opentom_task2_correct.sum(axis = 0).sum(axis = 1)/(opentom_task2_total.sum(axis = 0).sum(axis = 1) + eps))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing for Tasks 3 and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_bigtom_with_noise = []\n",
    "bigtom_noise_percepts = {i:[] for i in range(100)}\n",
    "final_opentom_with_noise = []\n",
    "opentom_noise_percepts = {i:[] for i in range(121)}\n",
    "random.seed(0)\n",
    "for instance in final_bigtom:\n",
    "    if instance['groundtruth_classification'] == 'easy_negative':\n",
    "        # find ID first\n",
    "        story_idx = instance['ID'].split('-')[0]\n",
    "        story_idx = int(story_idx)\n",
    "        bigtom_noise_percepts[story_idx].append(instance['percept_cue'])\n",
    "    else:\n",
    "        final_bigtom_with_noise.append(instance)\n",
    "# print(bigtom_noise_percepts[0])\n",
    "\n",
    "rem_list = []\n",
    "for instance in final_bigtom_with_noise:\n",
    "    story_idx = instance['ID'].split('-')[0]\n",
    "    story_idx = int(story_idx)\n",
    "    # put the noise into the dataset\n",
    "    instance['noise'] = []\n",
    "    # if (len(bigtom_noise_percepts[story_idx])==0):\n",
    "    #     print(instance)\n",
    "    # if story_idx == 91:\n",
    "    #     print(instance['ID'])\n",
    "    for _ in range(5):\n",
    "        if len(bigtom_noise_percepts[story_idx]) == 0:\n",
    "            # print(instance['ID'])\n",
    "            # final_bigtom_with_noise.remove(instance)\n",
    "            rem_list.append(instance)\n",
    "            break\n",
    "        else:\n",
    "            # print((bigtom_noise_percepts[story_idx]))\n",
    "            instance['noise'].append(random.choice(bigtom_noise_percepts[story_idx]))\n",
    "for story_idx in range(100):\n",
    "    if len(bigtom_noise_percepts[story_idx]) == 0:\n",
    "        del bigtom_noise_percepts[story_idx]\n",
    "for instance in rem_list:\n",
    "    final_bigtom_with_noise.remove(instance)\n",
    "            \n",
    "for instance in final_opentom:\n",
    "    if instance['groundtruth_classification'] == 'easy_negative':\n",
    "        # find ID first\n",
    "        story_idx = instance['ID'].split('-')[0]\n",
    "        story_idx = int(story_idx)\n",
    "        opentom_noise_percepts[story_idx].append(instance['percept_cue'])\n",
    "    else:\n",
    "        final_opentom_with_noise.append(instance)\n",
    "# print(bigtom_noise_percepts[0])\n",
    "rem_list = []\n",
    "for instance in final_opentom_with_noise:\n",
    "    story_idx = instance['ID'].split('-')[0]\n",
    "    story_idx = int(story_idx)\n",
    "    # put the noise into the dataset\n",
    "    instance['noise'] = []\n",
    "    # if (len(bigtom_noise_percepts[story_idx])==0):\n",
    "    #     print(instance)\n",
    "    for _ in range(5):\n",
    "        if len(opentom_noise_percepts[story_idx]) == 0:\n",
    "            # final_opentom_with_noise.remove(instance)\n",
    "            rem_list.append(instance)\n",
    "            break\n",
    "        else:\n",
    "            # print((bigtom_noise_percepts[story_idx]))\n",
    "            instance['noise'].append(random.choice(opentom_noise_percepts[story_idx]))\n",
    "            \n",
    "for story_idx in range(121):\n",
    "    if len(opentom_noise_percepts[story_idx]) == 0:\n",
    "        del opentom_noise_percepts[story_idx]\n",
    "for instance in rem_list:\n",
    "    final_bigtom_with_noise.remove(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "with open(\"llm_ready_bigtom_with_noise.jsonl\", \"w\") as file:\n",
    "    for item in final_bigtom_with_noise:\n",
    "        json_string = json.dumps(item)\n",
    "        file.write(json_string + '\\n')\n",
    "\n",
    "with open(\"llm_ready_opentom_with_noise.jsonl\", \"w\") as file:\n",
    "    for item in final_opentom_with_noise:\n",
    "        json_string = json.dumps(item)\n",
    "        file.write(json_string + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigtom_task3_ans = [{'ID': instance['ID'], 'groundtruth_classification': instance['groundtruth_classification']\n",
    "                     , 'sense': instance['sense'],\n",
    "                     'answer_order': [[0,1], [1,0],[0,1],[1,0], [0,1], [1,0],[0,1],[1,0]], # this is the f() that can map original order to postprocess order\n",
    "                     'llm_answer': ['X','X','X','X','X','X','X','X'],\n",
    "                     'true_answer': [instance['belief_change_label'], 1 - instance['belief_change_label'], instance['belief_change_label'], 1 - instance['belief_change_label'], instance['belief_change_label'], 1 - instance['belief_change_label'], instance['belief_change_label'], 1 - instance['belief_change_label']],\n",
    "                     'reasoning_content': ['X','X','X','X','X','X','X','X']} \n",
    "                    for instance in final_bigtom_with_noise]\n",
    "opentom_task3_ans = [{'ID': instance['ID'], 'groundtruth_classification': instance['groundtruth_classification']\n",
    "                     , 'sense': instance['sense'],\n",
    "                     'answer_order': [[0,1], [1,0],[0,1],[1,0], [0,1], [1,0],[0,1],[1,0]], # this is the f() that can map original order to postprocess order\n",
    "                     'llm_answer': ['X','X','X','X','X','X','X','X'],\n",
    "                     'true_answer': [instance['belief_change_label'], 1 - instance['belief_change_label'], instance['belief_change_label'], 1 - instance['belief_change_label'], instance['belief_change_label'], 1 - instance['belief_change_label'], instance['belief_change_label'], 1 - instance['belief_change_label']],\n",
    "                     'reasoning_content': ['X','X','X','X','X','X','X','X']} \n",
    "                    for instance in final_opentom_with_noise]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th story\n",
      "Time taken for these 5 stories: 346.8881878852844 seconds.\n",
      "1-th story\n"
     ]
    }
   ],
   "source": [
    "# BigToM first - Task 3\n",
    "model = \"deepseek-reasoner\"\n",
    "# positives\n",
    "count = 0\n",
    "input_tokens = 0\n",
    "output_tokens = 0\n",
    "begin = time.time()\n",
    "\n",
    "# for i in range(11,50):\n",
    "for i in range(len(bigtom_task3_ans)): # set to len(bigtom_task3_ans) later # 50 so far\n",
    "    print(f'{i}-th story')\n",
    "    for k in range(4):\n",
    "        #story, event, protag_name, percept, initial_belief\n",
    "        for j in range(2):# percept_order\n",
    "            story = final_bigtom_with_noise[i]['story']\n",
    "            event = final_bigtom_with_noise[i]['event']\n",
    "            protag_name = final_bigtom_with_noise[i]['protag_name']\n",
    "            percept_signal = final_bigtom_with_noise[i]['percept_cue']\n",
    "            # in each iteration, pick a different noise\n",
    "            percept_noise = final_bigtom_with_noise[i]['noise'][k]\n",
    "            \n",
    "            if (j==0):\n",
    "                percept = f\"\\n1. {percept_signal} \\n2. {percept_noise}\\n\"\n",
    "            else:\n",
    "                percept = f\"\\n1. {percept_noise} \\n2. {percept_signal}\\n\"\n",
    "            \n",
    "            \n",
    "            initial_belief = final_bigtom_with_noise[i]['initial_belief']\n",
    "            prompt = bigtom_system.format(story = story, event = event, protag_name = protag_name, percept = percept, initial_belief = initial_belief)\n",
    "            \n",
    "            prompt += bigtom_q1[k].format(protag_name = protag_name, initial_belief = initial_belief)\n",
    "            prompt += \"\\nProvide the answer as a single letter:\"\n",
    "\n",
    "            input_tokens += count_tokens(prompt)\n",
    "            \n",
    "            # print(prompt)\n",
    "            # print(\"input tokens = \", count_tokens(prompt), \". price (USD) is \", count_tokens(prompt)*30/1000000)\n",
    "            \n",
    "            \n",
    "            # Add back later\n",
    "            output = LM_generation(prompt, temperature = 0.5, max_tokens = 3, model = model)\n",
    "            \n",
    "            # Printouts - Remove later:\n",
    "            output = output[0]\n",
    "            reasoning_content = output.choices[0].message.reasoning_content\n",
    "            llm_answer = output.choices[0].message.content\n",
    "            llm_answer = llm_answer[0]\n",
    "            # print(reasoning_content)\n",
    "            # print(content)\n",
    "            \n",
    "            bigtom_task3_ans[i]['reasoning_content'][k] = reasoning_content\n",
    "            bigtom_task3_ans[i]['llm_answer'][k] = llm_answer\n",
    "\n",
    "                    \n",
    "            output_tokens += count_tokens(llm_answer)\n",
    "            save_jsonl(bigtom_task3_ans, f'bigtom_task3_ans_{model}.jsonl')\n",
    "            # print(\"output tokens = \", count_tokens(output[0]), \". price (USD) is \", count_tokens(output[0])*60/1000000)\n",
    "                    \n",
    "    if i % 5 == 0:\n",
    "        end = time.time()\n",
    "        print(f'Time taken for these 5 stories: {end-begin} seconds.')\n",
    "        begin = time.time()\n",
    "\n",
    "\n",
    "print(\"input tokens = \", input_tokens, \". price (USD) is \", input_tokens*30/1000000)\n",
    "print(\"output tokens = \", output_tokens, \". price (USD) is \", output_tokens*60/1000000)\n",
    "\n",
    "\n",
    "bigtom_task3_llm_answer = [instance['llm_answer'] for instance in bigtom_task3_ans]\n",
    "bigtom_task3_true_answer = [np.array(['A', 'B'])[np.array(instance['true_answer'])] for instance in bigtom_task3_ans]\n",
    "# bigtom_task3_llm_answer = bigtom_task3_llm_answer[0:50]\n",
    "# bigtom_task3_true_answer = bigtom_task3_true_answer[0:50]\n",
    "bigtom_task3_llm_answer = np.array(bigtom_task3_llm_answer)\n",
    "bigtom_task3_true_answer = np.array(bigtom_task3_true_answer)\n",
    "bigtom_task3_accuracy = (bigtom_task3_llm_answer == bigtom_task3_true_answer).mean(axis=1)\n",
    "gt_id = {'positive':0, 'hard_negative': 1}\n",
    "bigtom_task3_correct = np.zeros((100, 2, 8)) # groundtruth: pos, hard_neg, easy_neg\n",
    "bigtom_task3_total = np.zeros((100, 2, 8))\n",
    "for i, instance in enumerate(bigtom_task3_ans):\n",
    "    ider = instance['ID']\n",
    "    story_idx = int(ider.split('-')[0])\n",
    "    gt_idx = gt_id[instance['groundtruth_classification']]\n",
    "    sense_idx = sense_dict[instance['sense']]\n",
    "    bigtom_task3_total[story_idx][gt_idx][sense_idx] = 1\n",
    "    bigtom_task3_correct[story_idx][gt_idx][sense_idx] = bigtom_task3_accuracy[i]\n",
    "eps = 1e-10\n",
    "print(\"BigToM Task 3 TPR, TNR-hard: \", bigtom_task3_correct.sum(axis = 0).sum(axis = 1)/(bigtom_task3_total.sum(axis = 0).sum(axis = 1) + eps))\n",
    "\n",
    "# BigToM first - Task 3\n",
    "# positives\n",
    "count = 0\n",
    "input_tokens = 0\n",
    "output_tokens = 0\n",
    "begin = time.time()\n",
    "\n",
    "# for i in range(2):\n",
    "for i in range(len(opentom_task3_ans)): # set to len(bigtom_task3_ans) later # 50 so far\n",
    "    print(f'{i}-th story')\n",
    "    for k in range(4):\n",
    "        #story, event, protag_name, percept, initial_belief\n",
    "        for j in range(2):# percept_order\n",
    "            story = final_opentom_with_noise[i]['story']\n",
    "            protag_name = final_opentom_with_noise[i]['protag_name']\n",
    "            percept_signal = final_opentom_with_noise[i]['percept_cue']\n",
    "            # in each iteration, pick a different noise\n",
    "            percept_noise = final_opentom_with_noise[i]['noise'][k]\n",
    "            \n",
    "            if (j==0):\n",
    "                percept = f\"\\n1. {percept_signal} \\n2. {percept_noise}\\n\"\n",
    "            else:\n",
    "                percept = f\"\\n1. {percept_noise} \\n2. {percept_signal}\\n\"\n",
    "            \n",
    "            \n",
    "            initial_belief = final_opentom_with_noise[i]['initial_belief']\n",
    "            prompt = opentom_system.format(story = story, protag_name = protag_name, percept = percept, initial_belief = initial_belief)\n",
    "            \n",
    "            prompt += opentom_q1[k].format(protag_name = protag_name, initial_belief = initial_belief)\n",
    "            prompt += \"\\nProvide the answer as a single letter:\"\n",
    "\n",
    "            input_tokens += count_tokens(prompt)\n",
    "            \n",
    "            # print(prompt)\n",
    "            # print(\"input tokens = \", count_tokens(prompt), \". price (USD) is \", count_tokens(prompt)*30/1000000)\n",
    "            \n",
    "            \n",
    "            # Add back later\n",
    "            output = LM_generation(prompt, temperature = 0.5, max_tokens = 3, model = model)\n",
    "            \n",
    "            # Printouts - Remove later:\n",
    "            output = output[0]\n",
    "            reasoning_content = output.choices[0].message.reasoning_content\n",
    "            llm_answer = output.choices[0].message.content\n",
    "            llm_answer = llm_answer[0]\n",
    "            # print(reasoning_content)\n",
    "            # print(content)\n",
    "            \n",
    "            opentom_task3_ans[i]['reasoning_content'][k] = reasoning_content\n",
    "            opentom_task3_ans[i]['llm_answer'][k] = llm_answer\n",
    "\n",
    "                    \n",
    "            output_tokens += count_tokens(llm_answer)\n",
    "            save_jsonl(opentom_task3_ans, f'opentom_task3_ans_{model}.jsonl')\n",
    "            # print(\"output tokens = \", count_tokens(output[0]), \". price (USD) is \", count_tokens(output[0])*60/1000000)\n",
    "                    \n",
    "    if i % 5 == 0:\n",
    "        end = time.time()\n",
    "        print(f'Time taken for these 5 stories: {end-begin} seconds.')\n",
    "        begin = time.time()\n",
    "\n",
    "\n",
    "print(\"input tokens = \", input_tokens, \". price (USD) is \", input_tokens*30/1000000)\n",
    "print(\"output tokens = \", output_tokens, \". price (USD) is \", output_tokens*60/1000000)\n",
    "\n",
    "\n",
    "\n",
    "opentom_task3_llm_answer = [instance['llm_answer'] for instance in opentom_task3_ans]\n",
    "opentom_task3_true_answer = [np.array(['A', 'B'])[np.array(instance['true_answer'])] for instance in opentom_task3_ans]\n",
    "# bigtom_task3_llm_answer = bigtom_task3_llm_answer[0:50]\n",
    "# bigtom_task3_true_answer = bigtom_task3_true_answer[0:50]\n",
    "opentom_task3_llm_answer = np.array(opentom_task3_llm_answer)\n",
    "opentom_task3_true_answer = np.array(opentom_task3_true_answer)\n",
    "opentom_task3_accuracy = (opentom_task3_llm_answer == opentom_task3_true_answer).mean(axis=1)\n",
    "gt_id = {'positive':0, 'hard_negative': 1}\n",
    "opentom_task3_correct = np.zeros((121, 2, 8)) # groundtruth: pos, hard_neg, easy_neg\n",
    "opentom_task3_total = np.zeros((121, 2, 8))\n",
    "for i, instance in enumerate(opentom_task3_ans):\n",
    "    ider = instance['ID']\n",
    "    story_idx = int(ider.split('-')[0])\n",
    "    gt_idx = gt_id[instance['groundtruth_classification']]\n",
    "    sense_idx = sense_dict[instance['sense']]\n",
    "    opentom_task3_total[story_idx][gt_idx][sense_idx] = 1\n",
    "    opentom_task3_correct[story_idx][gt_idx][sense_idx] = opentom_task3_accuracy[i]\n",
    "eps = 1e-10\n",
    "print(\"OpenToM Task 3 TPR, TNR-hard: \", opentom_task3_correct.sum(axis = 0).sum(axis = 1)/(opentom_task3_total.sum(axis = 0).sum(axis = 1) + eps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigtom_task4_ans = [{'ID': instance['ID'], 'groundtruth_classification': instance['groundtruth_classification']\n",
    "                     , 'sense': instance['sense'],\n",
    "                     'answer_order': [], # this is the f() that can map original order to postprocess order\n",
    "                     'llm_answer': ['X','X','X','X','X','X','X','X','X','X'],\n",
    "                     'true_answer': [],\n",
    "                     'true_answer_og': option_dict[instance['new_belief_label']],\n",
    "                     'reasoning_content': ['X','X','X','X','X','X','X','X','X','X']} \n",
    "                    for instance in final_bigtom_with_noise]\n",
    "opentom_task4_ans = [{'ID': instance['ID'], 'groundtruth_classification': instance['groundtruth_classification']\n",
    "                     , 'sense': instance['sense'],\n",
    "                     'answer_order': [], # this is the f() that can map original order to postprocess order\n",
    "                     'llm_answer': ['X','X','X','X','X','X','X','X','X','X'],\n",
    "                     'true_answer': [],\n",
    "                     'true_answer_og': option_dict[instance['new_belief_label']],\n",
    "                     'reasoning_content': ['X','X','X','X','X','X','X','X','X','X']}  \n",
    "                    for instance in final_opentom_with_noise]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "task4_ans = [bigtom_task4_ans, opentom_task4_ans]\n",
    "for t in task4_ans:\n",
    "    for instance in t:\n",
    "        for _ in range(5):\n",
    "            randomizer = np.random.choice(np.arange(4), 4, replace=False) # 0 --> a0, 1 --> a1\n",
    "            instance['answer_order'].append(randomizer.tolist())\n",
    "            # instance['true_answer'].append(['A','B','C','D'][randomizer[instance['true_answer_og']]])\n",
    "            true_answer_idx = np.where(randomizer == instance['true_answer_og'])[0][0]\n",
    "            instance['true_answer'].append(['A','B','C','D'][true_answer_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in task4_ans:\n",
    "    for instance in t:\n",
    "        instance['answer_order'] = instance['answer_order'] + instance['answer_order']\n",
    "        instance['true_answer'] = instance['true_answer'] + instance['true_answer']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('opentom_task4_ans_deepseek-reasoner.jsonl') as f: # ambiguous story\n",
    "    opentom_task4_ans = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222-th story\n",
      "223-th story\n",
      "224-th story\n",
      "225-th story\n",
      "Time taken for these 5 stories: 1130.5392591953278 seconds.\n",
      "226-th story\n",
      "227-th story\n",
      "228-th story\n",
      "229-th story\n",
      "230-th story\n",
      "Time taken for these 5 stories: 1254.8644890785217 seconds.\n",
      "231-th story\n",
      "232-th story\n",
      "233-th story\n",
      "234-th story\n",
      "235-th story\n",
      "Time taken for these 5 stories: 1200.3369221687317 seconds.\n",
      "236-th story\n",
      "237-th story\n",
      "238-th story\n",
      "239-th story\n",
      "240-th story\n",
      "Time taken for these 5 stories: 910.0661590099335 seconds.\n",
      "241-th story\n",
      "242-th story\n",
      "243-th story\n",
      "244-th story\n",
      "245-th story\n",
      "Time taken for these 5 stories: 588.7686750888824 seconds.\n",
      "246-th story\n",
      "247-th story\n",
      "248-th story\n",
      "249-th story\n",
      "250-th story\n",
      "Time taken for these 5 stories: 1057.615769147873 seconds.\n",
      "251-th story\n",
      "252-th story\n",
      "253-th story\n",
      "254-th story\n",
      "255-th story\n",
      "Time taken for these 5 stories: 553.3187613487244 seconds.\n",
      "256-th story\n",
      "257-th story\n",
      "258-th story\n",
      "259-th story\n",
      "260-th story\n",
      "Time taken for these 5 stories: 798.5960559844971 seconds.\n",
      "261-th story\n",
      "262-th story\n",
      "263-th story\n",
      "264-th story\n",
      "265-th story\n",
      "Time taken for these 5 stories: 1565.4514870643616 seconds.\n",
      "266-th story\n",
      "267-th story\n",
      "268-th story\n",
      "269-th story\n",
      "270-th story\n",
      "Time taken for these 5 stories: 2021.942940235138 seconds.\n",
      "271-th story\n",
      "272-th story\n",
      "273-th story\n",
      "274-th story\n",
      "275-th story\n",
      "Time taken for these 5 stories: 2046.0946550369263 seconds.\n",
      "276-th story\n",
      "277-th story\n",
      "278-th story\n",
      "279-th story\n",
      "280-th story\n",
      "Time taken for these 5 stories: 2004.5792801380157 seconds.\n",
      "281-th story\n",
      "282-th story\n",
      "283-th story\n",
      "284-th story\n",
      "285-th story\n",
      "Time taken for these 5 stories: 2981.899117231369 seconds.\n",
      "286-th story\n",
      "287-th story\n",
      "288-th story\n",
      "289-th story\n",
      "290-th story\n",
      "Time taken for these 5 stories: 5696.409253120422 seconds.\n",
      "291-th story\n",
      "292-th story\n",
      "293-th story\n",
      "294-th story\n",
      "295-th story\n",
      "Time taken for these 5 stories: 7691.300806045532 seconds.\n",
      "296-th story\n",
      "297-th story\n",
      "298-th story\n",
      "299-th story\n",
      "300-th story\n",
      "Time taken for these 5 stories: 4784.977020978928 seconds.\n",
      "301-th story\n",
      "302-th story\n",
      "303-th story\n",
      "304-th story\n",
      "305-th story\n",
      "Time taken for these 5 stories: 4639.085151910782 seconds.\n",
      "306-th story\n",
      "307-th story\n",
      "308-th story\n",
      "309-th story\n",
      "310-th story\n",
      "Time taken for these 5 stories: 5829.316098213196 seconds.\n",
      "311-th story\n",
      "312-th story\n",
      "313-th story\n",
      "314-th story\n",
      "315-th story\n",
      "Time taken for these 5 stories: 4257.029698133469 seconds.\n",
      "316-th story\n",
      "317-th story\n",
      "318-th story\n",
      "319-th story\n",
      "320-th story\n",
      "Time taken for these 5 stories: 3768.747883081436 seconds.\n",
      "321-th story\n",
      "322-th story\n",
      "323-th story\n",
      "324-th story\n",
      "325-th story\n",
      "Time taken for these 5 stories: 3443.262263059616 seconds.\n",
      "326-th story\n",
      "327-th story\n",
      "328-th story\n",
      "329-th story\n",
      "330-th story\n",
      "Time taken for these 5 stories: 3805.253787279129 seconds.\n",
      "331-th story\n",
      "332-th story\n",
      "333-th story\n",
      "334-th story\n",
      "335-th story\n",
      "Time taken for these 5 stories: 3954.569742679596 seconds.\n",
      "336-th story\n",
      "337-th story\n",
      "338-th story\n",
      "339-th story\n",
      "340-th story\n",
      "Time taken for these 5 stories: 5493.414155006409 seconds.\n",
      "341-th story\n",
      "342-th story\n",
      "343-th story\n",
      "344-th story\n",
      "345-th story\n",
      "Time taken for these 5 stories: 3159.1491730213165 seconds.\n",
      "346-th story\n",
      "347-th story\n",
      "348-th story\n",
      "349-th story\n",
      "350-th story\n",
      "Time taken for these 5 stories: 3292.1200499534607 seconds.\n",
      "351-th story\n",
      "352-th story\n",
      "353-th story\n",
      "354-th story\n",
      "355-th story\n",
      "Time taken for these 5 stories: 3205.826751947403 seconds.\n",
      "356-th story\n",
      "357-th story\n",
      "358-th story\n",
      "359-th story\n",
      "360-th story\n",
      "Time taken for these 5 stories: 2351.9775030612946 seconds.\n",
      "361-th story\n",
      "362-th story\n",
      "363-th story\n",
      "364-th story\n",
      "365-th story\n",
      "Time taken for these 5 stories: 786.5270881652832 seconds.\n",
      "366-th story\n",
      "367-th story\n",
      "368-th story\n",
      "369-th story\n",
      "370-th story\n",
      "Time taken for these 5 stories: 934.2775459289551 seconds.\n",
      "371-th story\n",
      "372-th story\n",
      "373-th story\n",
      "374-th story\n",
      "375-th story\n",
      "Time taken for these 5 stories: 1143.532567024231 seconds.\n",
      "376-th story\n",
      "377-th story\n",
      "378-th story\n",
      "379-th story\n",
      "380-th story\n",
      "Time taken for these 5 stories: 1025.5643348693848 seconds.\n",
      "381-th story\n",
      "382-th story\n",
      "383-th story\n",
      "384-th story\n",
      "385-th story\n",
      "Time taken for these 5 stories: 1210.5939319133759 seconds.\n",
      "386-th story\n",
      "387-th story\n",
      "388-th story\n",
      "389-th story\n",
      "390-th story\n",
      "Time taken for these 5 stories: 818.150915145874 seconds.\n",
      "391-th story\n",
      "392-th story\n",
      "393-th story\n",
      "394-th story\n",
      "395-th story\n",
      "Time taken for these 5 stories: 787.8184559345245 seconds.\n",
      "396-th story\n",
      "397-th story\n",
      "398-th story\n",
      "399-th story\n",
      "400-th story\n",
      "Time taken for these 5 stories: 898.9095549583435 seconds.\n",
      "401-th story\n",
      "402-th story\n",
      "403-th story\n",
      "404-th story\n",
      "405-th story\n",
      "Time taken for these 5 stories: 901.1669721603394 seconds.\n",
      "406-th story\n",
      "407-th story\n",
      "408-th story\n",
      "409-th story\n",
      "410-th story\n",
      "Time taken for these 5 stories: 870.5550589561462 seconds.\n",
      "411-th story\n",
      "412-th story\n",
      "413-th story\n",
      "414-th story\n",
      "415-th story\n",
      "Time taken for these 5 stories: 773.9705708026886 seconds.\n",
      "416-th story\n",
      "417-th story\n",
      "418-th story\n",
      "419-th story\n",
      "420-th story\n",
      "Time taken for these 5 stories: 488.1099262237549 seconds.\n",
      "421-th story\n",
      "422-th story\n",
      "423-th story\n",
      "424-th story\n",
      "425-th story\n",
      "Time taken for these 5 stories: 1681.5030770301819 seconds.\n",
      "426-th story\n",
      "427-th story\n",
      "428-th story\n",
      "429-th story\n",
      "430-th story\n",
      "Time taken for these 5 stories: 1150.9838590621948 seconds.\n",
      "431-th story\n",
      "432-th story\n",
      "433-th story\n",
      "434-th story\n",
      "435-th story\n",
      "Time taken for these 5 stories: 556.2343480587006 seconds.\n",
      "436-th story\n",
      "437-th story\n",
      "438-th story\n",
      "439-th story\n",
      "440-th story\n",
      "Time taken for these 5 stories: 1346.6471650600433 seconds.\n",
      "441-th story\n",
      "442-th story\n",
      "443-th story\n",
      "444-th story\n",
      "445-th story\n",
      "Time taken for these 5 stories: 1368.4419870376587 seconds.\n",
      "446-th story\n",
      "447-th story\n",
      "448-th story\n",
      "449-th story\n",
      "450-th story\n",
      "Time taken for these 5 stories: 476.1497280597687 seconds.\n",
      "451-th story\n",
      "452-th story\n",
      "453-th story\n",
      "454-th story\n",
      "455-th story\n",
      "Time taken for these 5 stories: 458.24560499191284 seconds.\n",
      "456-th story\n",
      "457-th story\n",
      "458-th story\n",
      "459-th story\n",
      "460-th story\n",
      "Time taken for these 5 stories: 605.805046081543 seconds.\n",
      "461-th story\n",
      "462-th story\n",
      "463-th story\n",
      "464-th story\n",
      "465-th story\n",
      "Time taken for these 5 stories: 748.9287831783295 seconds.\n",
      "466-th story\n",
      "467-th story\n",
      "468-th story\n",
      "469-th story\n",
      "470-th story\n",
      "Time taken for these 5 stories: 893.1232481002808 seconds.\n",
      "471-th story\n",
      "472-th story\n",
      "473-th story\n",
      "474-th story\n",
      "475-th story\n",
      "Time taken for these 5 stories: 2043.6597821712494 seconds.\n",
      "476-th story\n",
      "477-th story\n",
      "478-th story\n",
      "479-th story\n",
      "480-th story\n",
      "Time taken for these 5 stories: 596.2225649356842 seconds.\n",
      "481-th story\n",
      "482-th story\n",
      "483-th story\n",
      "484-th story\n",
      "485-th story\n",
      "Time taken for these 5 stories: 1207.0886368751526 seconds.\n",
      "486-th story\n",
      "487-th story\n",
      "488-th story\n",
      "489-th story\n",
      "490-th story\n",
      "Time taken for these 5 stories: 1388.379508972168 seconds.\n",
      "491-th story\n",
      "492-th story\n",
      "493-th story\n",
      "494-th story\n",
      "495-th story\n",
      "Time taken for these 5 stories: 2724.2846291065216 seconds.\n",
      "496-th story\n",
      "497-th story\n",
      "498-th story\n",
      "499-th story\n",
      "500-th story\n",
      "Time taken for these 5 stories: 2441.5016610622406 seconds.\n",
      "501-th story\n",
      "502-th story\n",
      "503-th story\n",
      "504-th story\n",
      "505-th story\n",
      "Time taken for these 5 stories: 3270.0856330394745 seconds.\n",
      "506-th story\n",
      "507-th story\n",
      "508-th story\n"
     ]
    }
   ],
   "source": [
    "# BigToM first - Task 4\n",
    "model = \"deepseek-reasoner\"\n",
    "# positives\n",
    "count = 0\n",
    "input_tokens = 0\n",
    "output_tokens = 0\n",
    "begin = time.time()\n",
    "\n",
    "# # for i in range(20,50):\n",
    "for i in range(len(bigtom_task4_ans)): \n",
    "    print(f'{i}-th story')\n",
    "    for k in range(3): # only look at first 3\n",
    "        #story, event, protag_name, percept, initial_belief\n",
    "        for j in range(2):\n",
    "            story = final_bigtom_with_noise[i]['story']\n",
    "            event = final_bigtom_with_noise[i]['event']\n",
    "            protag_name = final_bigtom_with_noise[i]['protag_name']\n",
    "            percept_signal = final_bigtom_with_noise[i]['percept_cue']\n",
    "            # in each iteration, pick a different noise\n",
    "            percept_noise = final_bigtom_with_noise[i]['noise'][k]\n",
    "            \n",
    "            if (j==0):\n",
    "                percept = f\"\\n1. {percept_signal} \\n2. {percept_noise}\\n\"\n",
    "            else:\n",
    "                percept = f\"\\n1. {percept_noise} \\n2. {percept_signal}\\n\"\n",
    "                \n",
    "            initial_belief = final_bigtom_with_noise[i]['initial_belief']\n",
    "            prompt = bigtom_system.format(story = story, event = event, protag_name = protag_name, percept = percept, initial_belief = initial_belief)\n",
    "            \n",
    "            default_question = final_bigtom_with_noise[i]['default_question']\n",
    "            randomizer = np.array(bigtom_task4_ans[i]['answer_order'][k])\n",
    "            # print(final_bigtom[i]['answer_options'])\n",
    "            # print(randomizer)\n",
    "            first = final_bigtom_with_noise[i]['answer_options'][randomizer[0]]\n",
    "            second = final_bigtom_with_noise[i]['answer_options'][randomizer[1]]\n",
    "            third = final_bigtom_with_noise[i]['answer_options'][randomizer[2]]\n",
    "            fourth = final_bigtom_with_noise[i]['answer_options'][randomizer[3]]\n",
    "            prompt += bigtom_q2_prompt.format(default_question=default_question, first=first, second=second, third=third, fourth=fourth)\n",
    "            prompt += \"\\nProvide the answer as a single letter:\"\n",
    "\n",
    "            input_tokens += count_tokens(prompt)\n",
    "            \n",
    "            # print(prompt)\n",
    "            # print(\"input tokens = \", count_tokens(prompt), \". price (USD) is \", count_tokens(prompt)*30/1000000)\n",
    "            \n",
    "            \n",
    "            # Add back later\n",
    "            output = LM_generation(prompt, temperature = 0.5, max_tokens = 3, model = model)\n",
    "            \n",
    "            # Printouts - Remove later:\n",
    "            output = output[0]\n",
    "            reasoning_content = output.choices[0].message.reasoning_content\n",
    "            llm_answer = output.choices[0].message.content\n",
    "            llm_answer = llm_answer[0]\n",
    "            # print(reasoning_content)\n",
    "            # print(content)\n",
    "            \n",
    "            bigtom_task4_ans[i]['reasoning_content'][k + 5*j] = reasoning_content\n",
    "            bigtom_task4_ans[i]['llm_answer'][k + 5*j] = llm_answer\n",
    "\n",
    "                    \n",
    "            output_tokens += count_tokens(llm_answer)\n",
    "            \n",
    "            save_jsonl(bigtom_task4_ans, f'bigtom_task4_ans_{model}.jsonl')\n",
    "            # print(\"output tokens = \", count_tokens(output[0]), \". price (USD) is \", count_tokens(output[0])*60/1000000)\n",
    "                    \n",
    "    if i % 5 == 0:\n",
    "        end = time.time()\n",
    "        print(f'Time taken for these 5 stories: {end-begin} seconds.')\n",
    "        begin = time.time()\n",
    "\n",
    "\n",
    "print(\"input tokens = \", input_tokens, \". price (USD) is \", input_tokens*30/1000000)\n",
    "print(\"output tokens = \", output_tokens, \". price (USD) is \", output_tokens*60/1000000)\n",
    "\n",
    "\n",
    "bigtom_task4_llm_answer = [instance['llm_answer'] for instance in bigtom_task4_ans]\n",
    "bigtom_task4_true_answer = [instance['true_answer'] for instance in bigtom_task4_ans]\n",
    "bigtom_task4_llm_answer = bigtom_task4_llm_answer # remove slicing later\n",
    "bigtom_task4_true_answer = bigtom_task4_true_answer # remove slicing later\n",
    "bigtom_task4_llm_answer = np.array(bigtom_task4_llm_answer)\n",
    "bigtom_task4_true_answer = np.array(bigtom_task4_true_answer)\n",
    "bigtom_task4_accuracy = (bigtom_task4_llm_answer == bigtom_task4_true_answer).mean(axis=1)\n",
    "\n",
    "\n",
    "gt_id = {'positive':0, 'hard_negative': 1}\n",
    "bigtom_task4_correct = np.zeros((100, 2, 8)) # groundtruth: pos, hard_neg, easy_neg\n",
    "bigtom_task4_total = np.zeros((100, 2, 8))\n",
    "for i, instance in enumerate(bigtom_task4_ans): # remove slicing later\n",
    "    ider = instance['ID']\n",
    "    story_idx = int(ider.split('-')[0])\n",
    "    gt_idx = gt_id[instance['groundtruth_classification']]\n",
    "    sense_idx = sense_dict[instance['sense']]\n",
    "    bigtom_task4_total[story_idx][gt_idx][sense_idx] = 1\n",
    "    bigtom_task4_correct[story_idx][gt_idx][sense_idx] = bigtom_task4_accuracy[i]\n",
    "eps = 1e-10\n",
    "print(\"BigToM Task 4 TPR, TNR-hard: \", bigtom_task4_correct.sum(axis = 0).sum(axis = 1)/(bigtom_task4_total.sum(axis = 0).sum(axis = 1) + eps))\n",
    "\n",
    "\n",
    "# BigToM first - Task 1\n",
    "# positives\n",
    "count = 0\n",
    "input_tokens = 0\n",
    "output_tokens = 0\n",
    "begin = time.time()\n",
    "\n",
    "# for i in range(2):\n",
    "for i in range(222,len(opentom_task4_ans)): # set to len(bigtom_task1_ans) later # 50 so far\n",
    "    print(f'{i}-th story')\n",
    "    for k in range(3):\n",
    "        #story, event, protag_name, percept, initial_belief\n",
    "        for j in range(2):\n",
    "            story = final_opentom_with_noise[i]['story']\n",
    "            protag_name = final_opentom_with_noise[i]['protag_name']\n",
    "            percept_signal = final_opentom_with_noise[i]['percept_cue']\n",
    "            # in each iteration, pick a different noise\n",
    "            percept_noise = final_opentom_with_noise[i]['noise'][k]\n",
    "            \n",
    "            if (j==0):\n",
    "                percept = f\"\\n1. {percept_signal} \\n2. {percept_noise}\\n\"\n",
    "            else:\n",
    "                percept = f\"\\n1. {percept_noise} \\n2. {percept_signal}\\n\"\n",
    "                \n",
    "            initial_belief = final_opentom_with_noise[i]['initial_belief']\n",
    "            prompt = opentom_system.format(story = story, protag_name = protag_name, percept = percept, initial_belief = initial_belief)\n",
    "            \n",
    "            default_question = final_opentom_with_noise[i]['default_question']\n",
    "            randomizer = np.array(opentom_task4_ans[i]['answer_order'][k])\n",
    "            # print(final_bigtom[i]['answer_options'])\n",
    "            # print(randomizer)\n",
    "            first = final_opentom_with_noise[i]['answer_options'][randomizer[0]]\n",
    "            second = final_opentom_with_noise[i]['answer_options'][randomizer[1]]\n",
    "            third = final_opentom_with_noise[i]['answer_options'][randomizer[2]]\n",
    "            fourth = final_opentom_with_noise[i]['answer_options'][randomizer[3]]\n",
    "            prompt += opentom_q2_prompt.format(default_question=default_question, first=first, second=second, third=third, fourth=fourth)\n",
    "            \n",
    "            prompt += \"\\nProvide the answer as a single letter:\"\n",
    "\n",
    "            input_tokens += count_tokens(prompt)\n",
    "            \n",
    "            # print(prompt)\n",
    "            # print(\"input tokens = \", count_tokens(prompt), \". price (USD) is \", count_tokens(prompt)*30/1000000)\n",
    "            \n",
    "            \n",
    "            # Add back later\n",
    "            output = LM_generation(prompt, temperature = 0.5, max_tokens = 3, model = model)\n",
    "            \n",
    "            # Printouts - Remove later:\n",
    "            output = output[0]\n",
    "            reasoning_content = output.choices[0].message.reasoning_content\n",
    "            llm_answer = output.choices[0].message.content\n",
    "            llm_answer = llm_answer[0]\n",
    "            # print(reasoning_content)\n",
    "            # print(content)\n",
    "            \n",
    "            opentom_task4_ans[i]['reasoning_content'][k + 5*j] = reasoning_content\n",
    "            opentom_task4_ans[i]['llm_answer'][k + 5*j] = llm_answer\n",
    "\n",
    "                    \n",
    "            output_tokens += count_tokens(llm_answer)\n",
    "            save_jsonl(opentom_task4_ans, f'opentom_task4_ans_{model}.jsonl')\n",
    "            # print(\"output tokens = \", count_tokens(output[0]), \". price (USD) is \", count_tokens(output[0])*60/1000000)\n",
    "                    \n",
    "    if i % 5 == 0:\n",
    "        end = time.time()\n",
    "        print(f'Time taken for these 5 stories: {end-begin} seconds.')\n",
    "        begin = time.time()\n",
    "\n",
    "\n",
    "print(\"input tokens = \", input_tokens, \". price (USD) is \", input_tokens*30/1000000)\n",
    "print(\"output tokens = \", output_tokens, \". price (USD) is \", output_tokens*60/1000000)\n",
    "\n",
    "\n",
    "\n",
    "opentom_task4_llm_answer = [instance['llm_answer'] for instance in opentom_task4_ans]\n",
    "opentom_task4_true_answer = [instance['true_answer'] for instance in opentom_task4_ans]\n",
    "opentom_task4_llm_answer = opentom_task4_llm_answer # remove slicing later\n",
    "opentom_task4_true_answer = opentom_task4_true_answer # remove slicing later\n",
    "opentom_task4_llm_answer = np.array(opentom_task4_llm_answer)\n",
    "opentom_task4_true_answer = np.array(opentom_task4_true_answer)\n",
    "opentom_task4_accuracy = (opentom_task4_llm_answer == opentom_task4_true_answer).mean(axis=1)\n",
    "\n",
    "\n",
    "gt_id = {'positive':0, 'hard_negative': 1}\n",
    "opentom_task4_correct = np.zeros((121, 2, 8)) # groundtruth: pos, hard_neg, easy_neg\n",
    "opentom_task4_total = np.zeros((121, 2, 8))\n",
    "for i, instance in enumerate(opentom_task4_ans): # remove slicing later\n",
    "    ider = instance['ID']\n",
    "    story_idx = int(ider.split('-')[0])\n",
    "    gt_idx = gt_id[instance['groundtruth_classification']]\n",
    "    sense_idx = sense_dict[instance['sense']]\n",
    "    opentom_task4_total[story_idx][gt_idx][sense_idx] = 1\n",
    "    opentom_task4_correct[story_idx][gt_idx][sense_idx] = opentom_task4_accuracy[i]\n",
    "eps = 1e-10\n",
    "print(\"OpenToM Task 4 TPR, TNR-hard: \", opentom_task4_correct.sum(axis = 0).sum(axis = 1)/(opentom_task4_total.sum(axis = 0).sum(axis = 1) + eps))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COMP4222",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
